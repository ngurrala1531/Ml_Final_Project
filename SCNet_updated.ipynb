{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2ca661",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 341\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 341\u001b[0m     images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    342\u001b[0m     model \u001b[38;5;241m=\u001b[39m scnet101(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "## Created by: Jiang-Jiang Liu\n",
    "## Email: j04.liu@gmail.com\n",
    "## Copyright (c) 2020\n",
    "##\n",
    "## LICENSE file in the root directory of this source tree\n",
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\"\"\"SCNet variants\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "__all__ = ['SCNet', 'scnet50', 'scnet101', 'scnet50_v1d', 'scnet101_v1d']\n",
    "\n",
    "model_urls = {\n",
    "    'scnet50': 'https://backseason.oss-cn-beijing.aliyuncs.com/scnet/scnet50-dc6a7e87.pth',\n",
    "    'scnet50_v1d': 'https://backseason.oss-cn-beijing.aliyuncs.com/scnet/scnet50_v1d-4109d1e1.pth',\n",
    "    'scnet101': 'https://backseason.oss-cn-beijing.aliyuncs.com/scnet/scnet101-44c5b751.pth',\n",
    "    # 'scnet101_v1d': coming soon...\n",
    "}\n",
    "\n",
    "class SCConv(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride, padding, dilation, groups, pooling_r, norm_layer):\n",
    "        super(SCConv, self).__init__()\n",
    "        self.k2 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=pooling_r, stride=pooling_r),\n",
    "            nn.Conv2d(inplanes, planes, kernel_size=3, stride=1,\n",
    "                      padding=padding, dilation=dilation,\n",
    "                      groups=groups, bias=False),\n",
    "            norm_layer(planes),\n",
    "        )\n",
    "        self.k3 = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes, kernel_size=3, stride=1,\n",
    "                      padding=padding, dilation=dilation,\n",
    "                      groups=groups, bias=False),\n",
    "            norm_layer(planes),\n",
    "        )\n",
    "        self.k4 = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                      padding=padding, dilation=dilation,\n",
    "                      groups=groups, bias=False),\n",
    "            norm_layer(planes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        k2_out = F.interpolate(self.k2(x), identity.size()[2:]) if x.size()[2] > 1 and x.size()[3] > 1 else self.k2(x)\n",
    "        out = torch.sigmoid(torch.add(identity, k2_out))  # sigmoid(identity + k2)\n",
    "        out = torch.mul(self.k3(x), out)  # k3 * sigmoid(identity + k2)\n",
    "        out = self.k4(out)  # k4\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SCBottleneck(nn.Module):\n",
    "    \"\"\"SCNet SCBottleneck\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    pooling_r = 4 # down-sampling rate of the avg pooling layer in the K3 path of SC-Conv.\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 cardinality=1, bottleneck_width=32,\n",
    "                 avd=False, dilation=1, is_first=False,\n",
    "                 norm_layer=None):\n",
    "        super(SCBottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1_a = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1_a = norm_layer(group_width)\n",
    "        self.conv1_b = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1_b = norm_layer(group_width)\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1\n",
    "                                          )\n",
    "            stride = 1\n",
    "\n",
    "        self.k1 = nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        group_width, group_width, kernel_size=3, stride=stride,\n",
    "                        padding=dilation, dilation=dilation,\n",
    "                        groups=cardinality, bias=False),\n",
    "                    norm_layer(group_width),\n",
    "                    )\n",
    "\n",
    "        self.scconv = SCConv(\n",
    "            group_width, group_width, stride=stride,\n",
    "            padding=dilation, dilation=dilation,\n",
    "            groups=cardinality, pooling_r=self.pooling_r, norm_layer=norm_layer)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width * 2, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out_a= self.conv1_a(x)\n",
    "        out_a = self.bn1_a(out_a)\n",
    "        out_b = self.conv1_b(x)\n",
    "        out_b = self.bn1_b(out_b)\n",
    "        out_a = self.relu(out_a)\n",
    "        out_b = self.relu(out_b)\n",
    "\n",
    "        out_a = self.k1(out_a)\n",
    "        out_b = self.scconv(out_b)\n",
    "        out_a = self.relu(out_a)\n",
    "        out_b = self.relu(out_b)\n",
    "\n",
    "        if self.avd:\n",
    "            out_a = self.avd_layer(out_a)\n",
    "            out_b = self.avd_layer(out_b)\n",
    "\n",
    "        out = self.conv3(torch.cat([out_a, out_b], dim=1))\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SCNet(nn.Module):\n",
    "    \"\"\" SCNet Variants Definations\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block.\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained SCNet yielding a stride-8 model.\n",
    "    deep_stem : bool, default False\n",
    "        Replace 7x7 conv in input stem with 3 3x3 conv.\n",
    "    avg_down : bool, default False\n",
    "        Use AvgPool instead of stride conv when\n",
    "        downsampling in the bottleneck.\n",
    "    norm_layer : object\n",
    "        Normalization layer used (default: :class:`torch.nn.BatchNorm2d`).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\"\n",
    "        Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, groups=1, bottleneck_width=32,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 avd=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.avd = avd\n",
    "\n",
    "        super(SCNet, self).__init__()\n",
    "        conv_layer = nn.Conv2d\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, norm_layer):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, dilation=1, is_first=is_first,\n",
    "                                norm_layer=norm_layer))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, dilation=2, is_first=is_first,\n",
    "                                norm_layer=norm_layer))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, dilation=dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def scnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a SCNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SCNet(SCBottleneck, [3, 4, 6, 3],\n",
    "                deep_stem=False, stem_width=32, avg_down=False,\n",
    "                avd=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['scnet50']))\n",
    "    return model\n",
    "\n",
    "def scnet50_v1d(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a SCNet-50_v1d model described in\n",
    "    `Bag of Tricks <https://arxiv.org/pdf/1812.01187.pdf>`_.\n",
    "    `ResNeSt: Split-Attention Networks <https://arxiv.org/pdf/2004.08955.pdf>`_.\n",
    "\n",
    "    Compared with default SCNet(SCNetv1b), SCNetv1d replaces the 7x7 conv\n",
    "    in the input stem with three 3x3 convs. And in the downsampling block,\n",
    "    a 3x3 avg_pool with stride 2 is added before conv, whose stride is\n",
    "    changed to 1.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SCNet(SCBottleneck, [3, 4, 6, 3],\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['scnet50_v1d']))\n",
    "    return model\n",
    "\n",
    "def scnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a SCNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SCNet(SCBottleneck, [3, 4, 23, 3],\n",
    "                deep_stem=False, stem_width=64, avg_down=False,\n",
    "                avd=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['scnet101']))\n",
    "    return model\n",
    "\n",
    "def scnet101_v1d(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a SCNet-101_v1d model described in\n",
    "    `Bag of Tricks <https://arxiv.org/pdf/1812.01187.pdf>`_.\n",
    "    `ResNeSt: Split-Attention Networks <https://arxiv.org/pdf/2004.08955.pdf>`_.\n",
    "\n",
    "    Compared with default SCNet(SCNetv1b), SCNetv1d replaces the 7x7 conv\n",
    "    in the input stem with three 3x3 convs. And in the downsampling block,\n",
    "    a 3x3 avg_pool with stride 2 is added before conv, whose stride is\n",
    "    changed to 1.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = SCNet(SCBottleneck, [3, 4, 23, 3],\n",
    "                   deep_stem=True, stem_width=64, avg_down=True,\n",
    "                   avd=True, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['scnet101_v1d']))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    images = torch.rand(2, 3, 224, 224).cuda(0)\n",
    "    model = scnet101(pretrained=True)\n",
    "    model = model.cuda(0)\n",
    "    print(model(images).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c3593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
